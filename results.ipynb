{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vC80md0IUhDs",
        "outputId": "f4cb8e01-3ae3-4120-ed96-a00c6e231477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n",
            "/content/gdrive/My Drive/Research/UOH/AGenericALSSL_ESwA2023\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "#path\n",
        "%cd /content/gdrive/My Drive/Research/UOH/AGenericALSSL_ESwA2023/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "OI_OodnO4CW5",
        "outputId": "299145e6-085c-4737-ef83-470d4236c392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RUNS: 1 FOLDS: 5 \n",
            "\n",
            "------------------------------\n",
            "OBESIDAD\n",
            "bert\n",
            "------------------------------\n",
            "OBESIDAD_TIPOS\n",
            "bert\n",
            "------------------------------\n",
            "FUMADOR\n",
            "bert\n",
            "------------------------------\n",
            "AMAZON\n",
            "bert\n",
            "------------------------------\n",
            "IMDB\n",
            "bert\n",
            "------------------------------\n",
            "YELP\n",
            "bert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x3000 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Hyperparameters\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from matplotlib import pylab\n",
        "from collections import Counter\n",
        "import matplotlib\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "FONTSIZE = 15\n",
        "matplotlib.rcParams.update({'font.size': FONTSIZE})\n",
        "pylab.rcParams[\"legend.facecolor\"] = \"white\"\n",
        "pylab.rcParams['figure.facecolor'] = \"white\"\n",
        "\n",
        "DOMAIN = 'texts'\n",
        "\n",
        "FILENAMES = ['OBESIDAD', 'OBESIDAD_TIPOS', 'FUMADOR', 'AMAZON', 'IMDB', 'YELP']\n",
        "\n",
        "FILENAMES_ENG = ['OBESITY\\nSTATUS', 'OBESITY\\nTYPES', 'SMOKING\\nSTATUS', 'AMAZON', 'IMDB', 'YELP']\n",
        "\n",
        "#MODELS = ['svm', 'rf', 'nb-multinomial'] #run twice (classic and bert)\n",
        "MODELS = ['bert']\n",
        "\n",
        "titles = {'svm': 'SUPPORT VECTOR MACHINE', 'rf': 'RANDOM FOREST', 'nb-multinomial': 'NAÃVE BAYES'}\n",
        "colors = {'LINEAR' : 'olive', 'RBF': 'chocolate' ,\n",
        "          'GINI': 'orange', 'ENTROPY': 'seagreen',\n",
        "          'MULTINOMIAL': 'slateblue'}\n",
        "\n",
        "RUNS = 1\n",
        "FOLDS = 5\n",
        "\n",
        "fig = pylab.figure(1, figsize=(20,30))\n",
        "\n",
        "print('RUNS:', RUNS, 'FOLDS:', FOLDS, '\\n')\n",
        "\n",
        "for FILENAME in FILENAMES:\n",
        "\n",
        "  baseline_results = {}\n",
        "  print('-'*30)\n",
        "  print(FILENAME)\n",
        "\n",
        "  for model in MODELS:\n",
        "\n",
        "    params_aux = defaultdict(list)\n",
        "    params = defaultdict(list)\n",
        "\n",
        "    print(model)\n",
        "\n",
        "    if model != 'bert':\n",
        "      GRID_PARAMS = True\n",
        "    else:\n",
        "      GRID_PARAMS = False\n",
        "\n",
        "    results = defaultdict(list)\n",
        "    for r in range(RUNS):\n",
        "      for k in range(FOLDS):\n",
        "        with open( os.path.join( os.getcwd(), DOMAIN, 'out', 'RESULTS', FILENAME, model, FILENAME+'_results_'+model+'_r'+str(r+1)+'_f'+str(k+1)+'_p'+str(GRID_PARAMS)+'.pkl' ), 'rb') as a:\n",
        "          results_aux = pickle.load(a)\n",
        "\n",
        "          params_aux[model+'_params'].append( results_aux[model+'_params'] )\n",
        "          results_aux.pop(model+'_params')\n",
        "\n",
        "        for key in results_aux:\n",
        "          results[key] += results_aux[key]\n",
        "        del results_aux\n",
        "\n",
        "    for elem in params_aux[model+'_params']:\n",
        "      for dict_e in elem:\n",
        "        for key_e in dict_e:\n",
        "          if key_e != 'random_state' and key_e != 'probability':\n",
        "            params[key_e].append( dict_e[key_e] )\n",
        "    if 'svm' in model:\n",
        "      C_param = Counter(params['C']).most_common(1)[0][0]\n",
        "      kernel_param = Counter(params['kernel']).most_common(1)[0][0]\n",
        "      ax1 = pylab.subplot(len(MODELS), 1, MODELS.index(model)+1)\n",
        "\n",
        "      pylab.title(titles[model])\n",
        "      pylab.bar( [FILENAMES.index(FILENAME)], [C_param], color=colors[kernel_param.upper()] )\n",
        "      pylab.ylabel('C VALUE')\n",
        "      pylab.xticks( range(len(FILENAMES)), FILENAMES_ENG )\n",
        "      pylab.grid(True)\n",
        "    elif 'rf' in model:\n",
        "      n_estimators_param = Counter(params['n_estimators']).most_common(1)[0][0]\n",
        "      criterion_param = Counter(params['criterion']).most_common(1)[0][0]\n",
        "      ax2 = pylab.subplot(len(MODELS), 1, MODELS.index(model)+1)\n",
        "\n",
        "      pylab.title(titles[model])\n",
        "      pylab.bar( [FILENAMES.index(FILENAME)], [n_estimators_param], color=colors[criterion_param.upper()] )\n",
        "      pylab.ylabel('NUMBER OF ESTIMATORS')\n",
        "      pylab.xticks( range(len(FILENAMES)), FILENAMES_ENG )\n",
        "      pylab.grid(True)\n",
        "    elif 'nb' in model:\n",
        "      alpha_param = Counter(params['alpha']).most_common(1)[0][0]\n",
        "      ax3 = pylab.subplot(len(MODELS), 1, MODELS.index(model)+1)\n",
        "      pylab.title(titles[model])\n",
        "      pylab.bar( [FILENAMES.index(FILENAME)], [alpha_param], color=colors['MULTINOMIAL'] )\n",
        "      pylab.ylabel(r'$\\alpha$ VALUE')\n",
        "      pylab.xticks( range(len(FILENAMES)), FILENAMES_ENG )\n",
        "      pylab.grid(True)\n",
        "\n",
        "    for key in results:\n",
        "      acc = []\n",
        "      pre = []\n",
        "      rec = []\n",
        "      for true, pred in results[key]:\n",
        "\n",
        "        acc.append( 100*accuracy_score(true, pred) )\n",
        "        pre.append( 100*precision_score( true, pred, average='weighted' ) )\n",
        "        rec.append( 100*recall_score( true, pred, average='weighted' ) )\n",
        "\n",
        "      acc_mean = np.mean(acc)\n",
        "      pre_mean = np.mean(pre)\n",
        "      rec_mean = np.mean(rec)\n",
        "      f1_mean  = (2*pre_mean*rec_mean)/(pre_mean+rec_mean) \n",
        "      \n",
        "      #print('accuracy:', np.round( acc_mean, 2 ) )\n",
        "      #print('pre:', np.round( pre_mean, 2 )  )\n",
        "      #print('rec:', np.round( rec_mean, 2  ) )\n",
        "      #print('f1:',  np.round( f1_mean , 2 )  )\n",
        "\n",
        "      baseline_results[model+'_acc'] = acc_mean\n",
        "      baseline_results[model+'_pre'] = pre_mean\n",
        "      baseline_results[model+'_rec'] = rec_mean\n",
        "      baseline_results[model+'_f1' ] = f1_mean\n",
        "\n",
        "  with open( os.path.join( os.getcwd(), DOMAIN, 'out', 'RESULTS', FILENAME, FILENAME+'_baseline_results_p'+str(GRID_PARAMS)+'.pkl' ), 'wb') as a:\n",
        "    pickle.dump( baseline_results, a, protocol=2 )\n",
        "\n",
        "label = 'LINEAR'\n",
        "c1 = Patch(facecolor=colors[label], label=label)\n",
        "label = 'RBF'\n",
        "c2 = Patch(facecolor=colors[label], label=label)\n",
        "ax1.legend(handles=[c1,c2])\n",
        "\n",
        "label = 'ENTROPY'\n",
        "c1 =Patch(facecolor=colors[label], label=label)\n",
        "label = 'GINI'\n",
        "c2 = Patch(facecolor=colors[label], label=label)\n",
        "ax2.legend(handles=[c1,c2])\n",
        "\n",
        "label='MULTINOMIAL'\n",
        "c1 = Patch(facecolor=colors[label], label=label)\n",
        "ax3.legend(handles=[c1])\n",
        "\n",
        "pylab.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysis\n",
        "import os\n",
        "import re\n",
        "from matplotlib import pylab\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "FONTSIZE = 15\n",
        "\n",
        "sns.set_style(\"dark\")\n",
        "sns.set(font_scale=1.25) \n",
        "matplotlib.rcParams.update({'font.size': FONTSIZE})\n",
        "pylab.rcParams[\"legend.facecolor\"] = \"white\"\n",
        "pylab.rcParams['figure.facecolor'] = \"white\"\n",
        "\n",
        "METRIC = 'F1' #F1 ACC\n",
        "\n",
        "#DATASET = 'HGGB'\n",
        "#FILENAMES = ['OBESIDAD', 'OBESIDAD_TIPOS', 'FUMADOR']\n",
        "DATASET = 'UCI'\n",
        "FILENAMES = ['AMAZON', 'IMDB', 'YELP']\n",
        "\n",
        "curve_analysis = 'prob_thr' #'prob_thr' 'batch_size' \n",
        "\n",
        "if curve_analysis=='prob_thr':\n",
        "  AUXS = [0.85, 0.9, 0.95]\n",
        "  XLABEL = 'PROBABILITY THRESHOLD'\n",
        "  legend = 'probability threshold'\n",
        "elif curve_analysis=='batch_size':\n",
        "  AUXS = [32,64,128]\n",
        "  XLABEL = 'BATCH SIZE'\n",
        "  legend = 'batch'\n",
        "\n",
        "FILENAMES_ENG = {'OBESIDAD':'OBESITY STATUS', \n",
        "                 'OBESIDAD_TIPOS': 'OBESITY TYPES', \n",
        "                 'FUMADOR':'SMOKING STATUS', \n",
        "                 'AMAZON':'AMAZON', \n",
        "                 'IMDB': 'IMDB', \n",
        "                 'YELP':'YELP'}\n",
        "\n",
        "CLFS = ['bert', 'svm', 'rf', 'nb']\n",
        "colors = {'bert':'y', 'svm': 'r', 'rf':'g', 'nb': 'b'}\n",
        "ejey = {'OBESIDAD': 0.9, 'AMAZON':0.9,\n",
        "        'OBESIDAD_TIPOS': 0.63, 'IMDB': 0.63,\n",
        "        'FUMADOR': 0.36, 'YELP': 0.36   \n",
        "}\n",
        "\n",
        "mean_perf = []\n",
        "mean_pseu = []\n",
        "mean_perf_dict = {'bert':[], 'svm':[], 'rf':[], 'nb':[]}\n",
        "mean_pseu_dict = {'bert':[], 'svm':[], 'rf':[], 'nb':[]}\n",
        "\n",
        "fig = pylab.figure(1, figsize=(20,30))\n",
        "for filename in FILENAMES:\n",
        "  performance = {'bert':[], 'svm':[], 'rf':[], 'nb':[]}\n",
        "  pseudo = {'bert':[], 'svm':[], 'rf':[], 'nb':[]}\n",
        "\n",
        "  for aux in AUXS:\n",
        "    with open( os.path.join( os.getcwd(), 'texts', 'out', 'analysis', curve_analysis+'_'+str(aux)+'_'+DATASET+'_'+METRIC+'.txt' ), 'r'  ) as a:\n",
        "      data = a.read().split('\\n')[:-1]\n",
        "      for clf in CLFS:\n",
        "        for i in range(len(data)):\n",
        "          if re.findall(r'^%s' %clf, data[i]) and re.findall(r'%s\\s' %filename, data[i]):\n",
        "            val = float( data[i].split(' ')[-1] )\n",
        "            if (i%2)==0:\n",
        "              pseudo[clf].append(val)\n",
        "            else:\n",
        "              performance[clf].append(val)\n",
        "\n",
        "  W =150\n",
        "  pylab.figtext(0.5, ejey[filename]+0.006, '-'*W, ha='center', va='center', fontsize=22, color='gray')\n",
        "  pylab.figtext(0.5, ejey[filename]-0.006, r'$\\bf{%s}~DS$' %FILENAMES_ENG[filename].replace(' ', '~'), ha='center', va='center', fontsize=22)\n",
        "\n",
        "  pylab.subplot(3,2, 2*FILENAMES.index(filename)+1)\n",
        "  mean_C = []\n",
        "  for key in performance:\n",
        "    pylab.plot( [0,1,2], performance[key],  colors[key]+'-o', lw=2, ms=10, label=key.upper())\n",
        "    mean_C.append( performance[key] )\n",
        "    mean_perf_dict[key].append( performance[key] )\n",
        "  mean_C = np.mean(mean_C, axis=0)\n",
        "  mean_perf.append(mean_C)\n",
        "\n",
        "  pylab.xticks( [0,1,2], AUXS )\n",
        "  pylab.xlabel(XLABEL)\n",
        "  pylab.ylabel('AVERAGE '+METRIC+' (%)')\n",
        "  pylab.ylim([30, 100])\n",
        "  pylab.grid(True)\n",
        "\n",
        "  if FILENAMES.index(filename) == len(FILENAMES)-1:\n",
        "    pylab.legend( loc='upper center', bbox_to_anchor=(0.5, -0.15), shadow=False, ncol=4 )#, fontsize=FONTSIZE )\n",
        "\n",
        "  pylab.subplot(3,2, 2*FILENAMES.index(filename)+2)\n",
        "  mean_C = []\n",
        "  eps = 0\n",
        "  for key in pseudo:\n",
        "    pylab.bar( np.array([0,1,2])+eps, pseudo[key],  color=colors[key], width=0.1, label=key.upper())\n",
        "    eps+=0.1\n",
        "    mean_C.append( pseudo[key] )\n",
        "    mean_pseu_dict[key].append( pseudo[key] )\n",
        "\n",
        "  mean_C = np.mean(mean_C, axis=0)\n",
        "  mean_pseu.append(mean_C)\n",
        "  pylab.xticks( np.array([0,1,2])+0.1, AUXS )\n",
        "  pylab.xlabel(XLABEL)\n",
        "  pylab.ylabel('AVERAGE PSEUDO-LABELED SAMPLES (%)')\n",
        "  pylab.ylim([0, 100])\n",
        "  pylab.grid(True)\n",
        "\n",
        "  if FILENAMES.index(filename) == len(FILENAMES)-1:\n",
        "    pylab.legend( loc='upper center', bbox_to_anchor=(0.5, -0.15), shadow=False, ncol=4 )#, fontsize=FONTSIZE )\n",
        "\n",
        "pylab.show()\n",
        "\n",
        "print(DATASET)\n",
        "print(curve_analysis)\n",
        "print('clfs')\n",
        "for key in mean_pseu_dict:\n",
        "  print( 'Perf', key, np.round(np.mean(np.array(mean_perf_dict[key]),axis=0 ),2) )\n",
        "  print( 'Pseu', key, np.round(np.mean(np.array(mean_pseu_dict[key]),axis=0 ),2) )\n",
        "print('all')\n",
        "print( 'Perf:', np.round(np.mean(mean_perf, axis=0 ),2) )\n",
        "print( 'Pseu', np.round(np.mean(mean_pseu, axis=0 ),2) )"
      ],
      "metadata": {
        "id": "4CwROuseyXnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THwlT6gmlYhr"
      },
      "outputs": [],
      "source": [
        "#Learning curves results\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "from matplotlib import pylab\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from tabulate import tabulate\n",
        "from collections import Counter, defaultdict\n",
        "import re\n",
        "import copy\n",
        "from scipy import stats  \n",
        "from scipy.stats import wilcoxon\n",
        "\n",
        "sns.set_style(\"dark\")\n",
        "sns.set(font_scale=1.25) \n",
        "\n",
        "SSL_TYPES = ['del-each-one'] #'all' 'add-each-one' 'del-each-one' 'del-clustering'\n",
        "\n",
        "GRIDS = [True] #True False\n",
        "PGES = [None] #0.05 0.1 None\n",
        "\n",
        "DOMAIN = 'texts'\n",
        "THR_PRB = 0.9\n",
        "SAVE_TXT = False\n",
        "\n",
        "FILENAMES = ['OBESIDAD', 'OBESIDAD_TIPOS', 'FUMADOR']\n",
        "DATASET = 'HGGB'\n",
        "#FILENAMES = ['AMAZON', 'IMDB', 'YELP']\n",
        "#DATASET = 'UCI'\n",
        "\n",
        "MODELS = ['bert', 'svm', 'rf', 'nb-multinomial']\n",
        "\n",
        "CLASSES = {'OBESIDAD': 2, 'OBESIDAD_TIPOS':3, 'FUMADOR':2, 'AMAZON':2, 'IMDB':2, 'YELP':2}\n",
        "batch_aux = 64 #32 64 128 None\n",
        "BATCHES = {'OBESIDAD': batch_aux, 'OBESIDAD_TIPOS':batch_aux, 'FUMADOR':batch_aux, 'AMAZON':batch_aux, 'IMDB':batch_aux, 'YELP':batch_aux}\n",
        "LABELS_CLASSES = {\n",
        "           'OBESIDAD': ['NEGATIVE', 'POSITIVE'], \n",
        "           'OBESIDAD_TIPOS':['MODERATE', 'SEVERE', 'MORBID'],\n",
        "           'FUMADOR': ['NEGATIVE', 'POSITIVE'],\n",
        "           'AMAZON': ['NEGATIVE', 'POSITIVE'],\n",
        "           'IMDB': ['NEGATIVE', 'POSITIVE'],\n",
        "           'YELP': ['NEGATIVE', 'POSITIVE']\n",
        "           }\n",
        "\n",
        "RUNS = 1\n",
        "FOLDS = 5\n",
        "METRIC = 'F1' #F1 ACC\n",
        "FONTSIZE = 15\n",
        "matplotlib.rcParams.update({'font.size': FONTSIZE})\n",
        "pylab.rcParams[\"legend.facecolor\"] = \"white\"\n",
        "pylab.rcParams['figure.facecolor'] = \"white\"\n",
        "\n",
        "ejey = {'OBESIDAD': 0.9, 'AMAZON':0.9,\n",
        "        'OBESIDAD_TIPOS': 0.63, 'IMDB': 0.63,\n",
        "        'FUMADOR': 0.36, 'YELP': 0.36   \n",
        "}\n",
        "\n",
        "curve_analysis = None #None 'prob_thr' 'batch_size'\n",
        "\n",
        "CURVES = {\n",
        "          #primero ssl por axis\n",
        "          'bert': ['_lc_sslal_', '_lc_al_'],#, '_lc_pl_'], \n",
        "          'svm': ['_lc_sslal_', '_lc_al_'],#, '_lc_pl_'], \n",
        "          'rf': ['_lc_sslal_', '_lc_al_'],#, '_lc_pl_'], \n",
        "          'nb-multinomial': ['_lc_sslal_', '_lc_al_'],#, '_lc_pl_'],\n",
        "          }\n",
        "\n",
        "if curve_analysis is not None:\n",
        "  for key in CURVES:\n",
        "    CURVES[key] = [ CURVES[key][0] ]\n",
        "\n",
        "COLORS = {\n",
        "          #'bert_lc_pl_': 'y:o',\n",
        "          'bert_lc_al_': 'y-',\n",
        "          'bert_lc_sslal_': 'y--',\n",
        "          #'svm_lc_pl_': 'r:o',\n",
        "          'svm_lc_al_': 'r-',\n",
        "          'svm_lc_sslal_': 'r--',\n",
        "          #'rf_lc_pl_': 'g:o',\n",
        "          'rf_lc_al_': 'g-',\n",
        "          'rf_lc_sslal_': 'g--',\n",
        "          #'nb-multinomial_lc_pl_': 'b:o',\n",
        "          'nb-multinomial_lc_al_': 'b-',\n",
        "          'nb-multinomial_lc_sslal_': 'b--'\n",
        "}\n",
        "\n",
        "COLORS_C = [ COLORS[key+'_lc_sslal_'][0]  for key in MODELS ]\n",
        "\n",
        "LABELS = {\n",
        "          'bert': 'BERT-BASELINE',\n",
        "          #'bert_lc_pl_': 'BERT-PL',\n",
        "          'bert_lc_al_': 'BERT-AL',\n",
        "          'bert_lc_sslal_': 'BERT-SSL',\n",
        "          'svm': 'SVM-BASELINE',\n",
        "          #'svm_lc_pl_': 'SVM-PL',\n",
        "          'svm_lc_al_': 'SVM-AL',\n",
        "          'svm_lc_sslal_': 'SVM-SSL',\n",
        "          'rf': 'RF-BASELINE',\n",
        "          #'rf_lc_pl_': 'RF-PL',\n",
        "          'rf_lc_al_': 'RF-AL',\n",
        "          'rf_lc_sslal_': 'RF-SSL',\n",
        "          'nb-multinomial': 'NB-BASELINE',\n",
        "          #'nb-multinomial_lc_pl_': 'NB-PL',\n",
        "          'nb-multinomial_lc_al_': 'NB-AL',\n",
        "          'nb-multinomial_lc_sslal_': 'NB-SSL'\n",
        "          }\n",
        "TITLES = {\n",
        "          'OBESIDAD': 'OBESITY STATUS',\n",
        "          'OBESIDAD_TIPOS': 'OBESITY TYPES',\n",
        "          'FUMADOR': 'SMOKING STATUS',\n",
        "          'AMAZON': 'AMAZON',\n",
        "          'IMDB': 'IMDB', \n",
        "          'YELP': 'YELP'\n",
        "}\n",
        "\n",
        "print('RUNS:', RUNS, 'FOLDS:', FOLDS, '\\n')\n",
        "\n",
        "if curve_analysis == 'batch_size':\n",
        "  a_filename = open( os.path.join( os.getcwd(), 'texts', 'out', 'analysis', curve_analysis+'_'+str(batch_aux)+'_'+DATASET+'_'+METRIC+'.txt' ), 'w'  )\n",
        "elif curve_analysis == 'prob_thr':\n",
        "  a_filename = open( os.path.join( os.getcwd(), 'texts', 'out', 'analysis', curve_analysis+'_'+str(THR_PRB)+'_'+DATASET+'_'+METRIC+'.txt' ), 'w'  )\n",
        "\n",
        "if SAVE_TXT:\n",
        "  a_txt = open( os.path.join( os.getcwd(), DOMAIN, 'out', 'plots', DATASET, DATASET+'.txt' ) , 'w')\n",
        "for SSL_TYPE in SSL_TYPES:\n",
        "  if SAVE_TXT:\n",
        "    a_txt.write('-'*30+'\\n')\n",
        "    a_txt.write('SSL_TYPE: '+SSL_TYPE+'\\n')\n",
        "  for GRID_PARAMS in GRIDS:\n",
        "    if SAVE_TXT:\n",
        "      a_txt.write('GRID_PARAMS: '+str(GRID_PARAMS)+'\\n')\n",
        "    for PGE in PGES:\n",
        "      if SAVE_TXT:\n",
        "        a_txt.write('PGE: '+str(PGE)+'\\n')\n",
        "\n",
        "      fig = pylab.figure(1, figsize=(20,30))\n",
        "      idx = -1\n",
        "      scores_lc = 'lc_al'\n",
        "\n",
        "      average_all_cases = []\n",
        "      average_all_cases_performance = []\n",
        "\n",
        "      c_H_all = []\n",
        "      c_C_all = []\n",
        "\n",
        "      for FILENAME in FILENAMES:\n",
        "        print(FILENAME)\n",
        "\n",
        "        average_all_cases_clf = defaultdict(list)\n",
        "        average_all_cases_performance_clf = defaultdict(list)\n",
        "\n",
        "        mean_error = defaultdict(list)\n",
        "        mean_pseudo = defaultdict(list)\n",
        "\n",
        "        NCLASSES = CLASSES[FILENAME]\n",
        "        BATCH = BATCHES[FILENAME]\n",
        "        idx+=2\n",
        "\n",
        "        curves_all = {}\n",
        "        samples_model_curve = {}\n",
        "        C_all = defaultdict(list)\n",
        "\n",
        "        with open( os.path.join( os.getcwd(), DOMAIN, 'out', 'RESULTS', FILENAME, FILENAME+'_baseline_results_p'+str(GRID_PARAMS)+'.pkl' ), 'rb') as a:\n",
        "          baseline_results = pickle.load(a) \n",
        "\n",
        "        for model in MODELS:\n",
        "          print(model)\n",
        "\n",
        "          if model != 'bert':\n",
        "            GRID_PARAMS = True\n",
        "          else:\n",
        "            GRID_PARAMS = False\n",
        "\n",
        "          A, B = [], []\n",
        "\n",
        "          for curve in CURVES[model]:\n",
        "            print(curve)\n",
        "            \n",
        "            #all\n",
        "            curve_runs = []\n",
        "            results_lc = defaultdict(list)\n",
        "\n",
        "            if scores_lc in curve:\n",
        "              scores_runs = []\n",
        "\n",
        "            if 'lc_ssl' in curve:\n",
        "\n",
        "              samples_runs = []\n",
        "              distribution_runs = []\n",
        "              p_qs = []\n",
        "              p_val = []\n",
        "\n",
        "            for r in range(RUNS):\n",
        "              for k in range(FOLDS):\n",
        "                if 'lc_ssl' not in curve:\n",
        "                  with open( os.path.join( os.getcwd(), DOMAIN, 'out', 'BATCH'+str(BATCH), FILENAME, model, FILENAME+'_results'+curve+model+'_r'+str(r+1)+'_f'+str(k+1)+'_p'+str(GRID_PARAMS)+'.pkl' ), 'rb') as a:\n",
        "                    results_lc_aux = pickle.load(a) \n",
        "                else:\n",
        "                  with open( os.path.join( os.getcwd(), DOMAIN, 'out', 'BATCH'+str(BATCH), 'PROB'+str(THR_PRB), FILENAME, model, FILENAME+'_results'+curve+model+'_r'+str(r+1)+'_f'+str(k+1)+'_p'+str(GRID_PARAMS)+'_'+SSL_TYPE+'_'+str(PGE)+'.pkl' ), 'rb') as a:\n",
        "                    results_lc_aux = pickle.load(a) \n",
        "\n",
        "                  results_lc_aux.pop(model+'_params')\n",
        "\n",
        "                for key in results_lc_aux:\n",
        "                  results_lc[key] += results_lc_aux[key]\n",
        "                del results_lc_aux\n",
        "\n",
        "              for f in range(FOLDS):\n",
        "                \n",
        "                #all\n",
        "                curve_fold = []\n",
        "                \n",
        "                if scores_lc in curve:\n",
        "                  scores_fold = []\n",
        "\n",
        "                if 'lc_ssl' in curve:  \n",
        "\n",
        "                  samples_fold = []\n",
        "                  distribution_fold = []\n",
        "                  qs_fold = []\n",
        "                  val_fold = []\n",
        "\n",
        "                for key in results_lc:\n",
        "                  true = None\n",
        "                  if re.findall(r'^(AL|PL|SSL)', key):\n",
        "                    true = results_lc[key][f][0]\n",
        "                    for pred in results_lc[key][f][1]:\n",
        "                      if METRIC == 'ACC':\n",
        "                        curve_fold.append( 100*accuracy_score(true, pred) )\n",
        "                      elif METRIC == 'F1':\n",
        "                        curve_fold.append( 100*f1_score(true, pred, average='weighted') )\n",
        "                  else:\n",
        "                    if 'scores' in key:\n",
        "                      x_axis = results_lc[key][f][0]\n",
        "\n",
        "                    if 'scores' in key and scores_lc in curve:\n",
        "                      for batch in results_lc[key][f][1]:\n",
        "                        if len(batch)>0:\n",
        "                          scores_fold.append( np.var(batch[:BATCH] ) )\n",
        "                        else:\n",
        "                          scores_fold.append(0)\n",
        "                    elif 'samples' in key: #SSL-samples\n",
        "                      samples_fold.extend( results_lc[key][f][1] )\n",
        "                    elif 'distribution' in key:\n",
        "                      for batch in results_lc[key][f][1]:\n",
        "                        distribution_fold.append( Counter(batch) )\n",
        "                    elif 'probs_val' in key: #select by batch\n",
        "                      val_fold.extend( results_lc[key][f][1] )\n",
        "                    elif 'probs_qs' in key:  #select by batch\n",
        "                      qs_fold.extend( results_lc[key][f][1] )\n",
        "\n",
        "                curve_runs.append( curve_fold )\n",
        "\n",
        "                if scores_lc in curve:\n",
        "                  scores_runs.append(scores_fold)\n",
        "\n",
        "                if 'lc_ssl' in curve:\n",
        "                  \n",
        "                  samples_runs.append( samples_fold )\n",
        "                  distribution_runs.append( distribution_fold )\n",
        "                  p_qs.append( qs_fold )\n",
        "                  p_val.append( val_fold )\n",
        "\n",
        "            ########################################################################\n",
        "            max_points = max([len(p) for p in curve_runs])\n",
        "            for idf in range(len(curve_runs)):\n",
        "              if len(curve_runs[idf])<max_points:\n",
        "                curve_runs[idf].append( curve_runs[idf][-1] )\n",
        "\n",
        "                if scores_lc in curve:\n",
        "                  scores_runs[idf].append( scores_runs[idf][-1] )\n",
        "            ########################################################################\n",
        "\n",
        "            curve_runs = np.array(curve_runs)\n",
        "            error_curve_runs = np.std(curve_runs, axis = 0)\n",
        "            curve_runs = np.mean(curve_runs, axis=0)\n",
        "\n",
        "            if scores_lc in curve:\n",
        "              scores_runs = np.array(scores_runs)\n",
        "              scores_runs = np.mean(scores_runs, axis=0)\n",
        "\n",
        "            if 'lc_ssl' in curve:\n",
        "\n",
        "              A = copy.deepcopy(curve_runs)\n",
        "\n",
        "              ########################################################################\n",
        "              max_points = max([len(p) for p in samples_runs])\n",
        "              for idf in range(len(samples_runs)):\n",
        "                if len(samples_runs[idf])<max_points:\n",
        "                  samples_runs[idf].append( samples_runs[idf][-1] )\n",
        "                  #just for obesity\n",
        "                  distribution_runs[idf].append( {'C':0, 'H':1} )\n",
        "              ########################################################################\n",
        "\n",
        "              samples_runs = np.array(samples_runs)\n",
        "              samples_runs = np.mean(samples_runs, axis=0)\n",
        "              samples_model_curve[model+curve] = samples_runs\n",
        "\n",
        "              c_H = 0\n",
        "              c_C = 0\n",
        "              for p in range(len(samples_runs)):\n",
        "                C_all[ re.sub(r'\\-\\w+$', '', model).upper() ].append([])\n",
        "                for f in range(FOLDS):\n",
        "                  H_aux = distribution_runs[f][p]['H']\n",
        "                  C_aux = distribution_runs[f][p]['C']\n",
        "                  C_all[ re.sub(r'\\-\\w+$', '', model).upper() ][p].append( 100*C_aux/(H_aux+C_aux) )\n",
        "\n",
        "                  average_all_cases_clf[model+'_'+FILENAME].append( 100*C_aux/(H_aux+C_aux) )\n",
        "\n",
        "                  mean_pseudo[model].append( 100*C_aux/(H_aux+C_aux) )\n",
        "\n",
        "                  c_H += H_aux\n",
        "                  c_C += C_aux\n",
        "\n",
        "              c_H /= (RUNS*FOLDS)\n",
        "              c_C /= (RUNS*FOLDS)\n",
        "\n",
        "              c_H_all.append( 100*c_H/x_axis[-1] )\n",
        "              c_C_all.append( 100*c_C/x_axis[-1] )\n",
        "\n",
        "              print( model, c_H, c_C, x_axis[-1], 'SSL-AL', round(100*c_C/x_axis[-1], 2), '&', 100-round(100*c_C/x_axis[-1], 2) )\n",
        "\n",
        "            elif 'lc_al' in curve:\n",
        "              B = copy.deepcopy(curve_runs)\n",
        "\n",
        "            ax = pylab.subplot(len(FILENAMES), 2, idx)\n",
        "\n",
        "            mean_error[model].append( curve_runs )\n",
        "\n",
        "            pylab.plot(np.arange(len(x_axis))+1, curve_runs, COLORS[model+curve], label = LABELS[model+curve], lw=2 )\n",
        "\n",
        "            if 'lc_ssl' in curve:\n",
        "              average_all_cases_performance.append( np.mean(curve_runs) )\n",
        "              average_all_cases_performance_clf[model+'_'+FILENAME].append( np.mean(curve_runs) )\n",
        "\n",
        "            #baseline\n",
        "            if '_al_' in curve:\n",
        "              pylab.axhline( baseline_results[model+'_'+METRIC.lower()], c=COLORS[model+curve][0], linestyle = ':', label = LABELS[model], lw=2 )\n",
        "\n",
        "            pylab.fill_between(np.arange(len(x_axis))+1, curve_runs-error_curve_runs, curve_runs+error_curve_runs, facecolor=COLORS[model+curve][0],  alpha=0.05)\n",
        "            pylab.grid(True)  \n",
        "            pylab.xlabel('Iteration number'.upper() )\n",
        "            pylab.ylabel( ('Average '+METRIC+' (%)').upper() )\n",
        "            pylab.ylim([30, 105])\n",
        "            if idx == len(FILENAMES):\n",
        "\n",
        "              pylab.legend( loc='upper center', bbox_to_anchor=(0.5, -1.4), shadow=False, ncol=3 )\n",
        "\n",
        "            curves_all[model+curve] = curve_runs\n",
        "\n",
        "        W = 150\n",
        "\n",
        "        pylab.figtext(0.5, ejey[FILENAME]+0.006, '-'*W, ha='center', va='center', fontsize=22, color='gray')\n",
        "        pylab.figtext(0.5, ejey[FILENAME]-0.006, r'$\\bf{%s~DS}$' %TITLES[FILENAME].replace(' ', '~'), ha='center', va='center', fontsize=22)\n",
        "\n",
        "        labels = np.arange(0, len(x_axis))\n",
        "        C_all_average = {}\n",
        "        average_C = []\n",
        "        for keyC in C_all:\n",
        "          array_aux = copy.deepcopy( np.array(C_all[keyC]) )\n",
        "          C_all_average[keyC] = np.mean(array_aux, axis=1)\n",
        "          average_C.append(C_all_average[keyC])\n",
        "          average_all_cases.extend(np.mean(array_aux, axis=1))\n",
        "\n",
        "        df = pd.DataFrame( C_all_average, index=labels)\n",
        "\n",
        "        ax = pylab.subplot(len(FILENAMES), 2, idx+1)\n",
        "\n",
        "        df.plot(kind='bar', ax=ax, stacked=False, legend=False, color=COLORS_C, width=1.5)\n",
        "        pylab.xlabel('Iteration number'.upper() )\n",
        "        pylab.ylabel('Pseudo-labeled samples (%)'.upper() )\n",
        "        pylab.ylim( [0, 110] )\n",
        "        pylab.xticks( np.arange(len(x_axis)), np.arange(len(x_axis))+1  )\n",
        "        pylab.grid(True)\n",
        "\n",
        "        if idx == len(FILENAMES):\n",
        "          pylab.legend( loc='upper center', bbox_to_anchor=(0.5, -1.5), shadow=False, ncol=5 )\n",
        "          \n",
        "        if curve_analysis is not None:\n",
        "          for key_c in average_all_cases_performance_clf:\n",
        "            a_filename.write(key_c+' '+str( np.round( np.mean(average_all_cases_clf[key_c]),2 ) )+'\\n')\n",
        "            a_filename.write(key_c+' '+str( np.round( np.mean(average_all_cases_performance_clf[key_c]),2 ) )+'\\n')\n",
        "\n",
        "        if curve_analysis is None:\n",
        "          for key_m in mean_error:\n",
        "\n",
        "            ssl_curve_error,  al_curve_error = mean_error[key_m]\n",
        "            ssl_curve_error = np.array(ssl_curve_error)\n",
        "            al_curve_error = np.array(al_curve_error)\n",
        "            l_error = len(ssl_curve_error)\n",
        "\n",
        "            print(key_m)\n",
        "            print( 'mean error:', (ssl_curve_error-al_curve_error).sum()/l_error )\n",
        "            print( 'mean pseudo:', np.mean(mean_pseudo[key_m]) )\n",
        "            print('p-value<0.05', wilcoxon(ssl_curve_error, al_curve_error)[1]<0.05 )\n",
        "\n",
        "        values = range(60,100)\n",
        "        columns_df = []\n",
        "        x_y_curves = {'0_'+METRIC.upper()+'(%)>=': values}  \n",
        "        for key in curves_all:\n",
        "          x_y = []\n",
        "          results_lc = copy.deepcopy( curves_all[key] )\n",
        "          for val in values:\n",
        "            xy = '-'\n",
        "            for index in range(len(x_axis)):\n",
        "              if results_lc[index]>=val and xy=='-':\n",
        "                if 'ssl' not in key:\n",
        "                  xy = x_axis[index]\n",
        "                else:\n",
        "                  xy = int(samples_model_curve[key][index])\n",
        "            x_y.append(xy)\n",
        "          if '_al_' in key:\n",
        "            key_aux_df = '2_'+key\n",
        "          elif '_sslal_' in key:\n",
        "            key_aux_df = '1_'+key\n",
        "          columns_df.append( key_aux_df )\n",
        "          x_y_curves[key_aux_df] = x_y\n",
        "        columns_df.append('0_'+METRIC.upper()+'(%)>=')\n",
        "        columns_df = sorted(columns_df)\n",
        "        df = pd.DataFrame.from_dict(x_y_curves)\n",
        "        df = df[columns_df]\n",
        "\n",
        "        table_df = tabulate(df, headers = 'keys', tablefmt = 'psql', showindex=False).replace('|', '&') \n",
        "        table_df = re.sub(r'^\\&', ' ', table_df, flags=re.M)\n",
        "        table_df = re.sub(r'\\&$', r'\\\\\\\\ \\\\hline', table_df, flags=re.M)\n",
        "        print ( table_df ) \n",
        "\n",
        "        with open( os.path.join( os.getcwd(), DOMAIN, 'out', 'plots', DATASET, 'Tables', FILENAME+'_SSL_'+SSL_TYPE+'_GRID_'+str(GRID_PARAMS)+'_PGE_'+str(PGE)+'.txt' ), 'w' ) as a:\n",
        "          a.write( tabulate(df, headers = 'keys', tablefmt = 'psql') )\n",
        "\n",
        "      print(  'SSL-AL (all)', round( np.mean(c_C_all), 2), '&', 100-round( np.mean(c_C_all), 2) )\n",
        "      print( 'average samples:', np.mean(average_all_cases) )\n",
        "      print( 'average acc (%):', np.mean(average_all_cases_performance) )\n",
        "\n",
        "      pylab.savefig( os.path.join( os.getcwd(), DOMAIN, 'out', 'plots', DATASET, 'Figures', '-'.join(FILENAMES)+'_SSL_'+SSL_TYPE+'_GRID_'+str(GRID_PARAMS)+'_PGE_'+str(PGE)+'.png' ), bbox_inches='tight' )\n",
        "\n",
        "      pylab.show()\n",
        "\n",
        "      del fig\n",
        "\n",
        "      if SAVE_TXT:\n",
        "        a_txt.write('Average (% anotacion): '+str(np.round(np.mean(average_all_cases),2))+'\\n')\n",
        "        a_txt.write('Average (% acc): '+str(np.round(np.mean(average_all_cases_performance),2))+'\\n')\n",
        "        a_txt.write('-'*30+'\\n')\n",
        "\n",
        "if SAVE_TXT:\n",
        "  a_txt.close()\n",
        "\n",
        "if curve_analysis is not None:  \n",
        "  a_filename.close()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}